{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b009850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "import zipfile\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd483a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_URL = 'http://files.grouplens.org/datasets/movielens/ml-100k.zip'\n",
    "DATASET_ARCHIVE = 'ml-100k.zip'\n",
    "\n",
    "request.urlretrieve(DATASET_URL, DATASET_ARCHIVE)\n",
    "with zipfile.ZipFile(DATASET_ARCHIVE) as archive:\n",
    "    archive.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909c5bad",
   "metadata": {},
   "source": [
    "### 2. Prepare error metrics: RMSE\n",
    "Your Task:\n",
    "1. Prepare 2 functions that will calculate the goodness of fit: RMSE and HR@n\n",
    "2. RMSE:\n",
    "$RMSE(R,\\hat{R})=\\sqrt{1/n \\sum{(r - \\hat{r})^2}}$ <br/>\n",
    "$n\\  - \\text{# ratings in Y}$ <br/>\n",
    "$R\\  - \\text{ground true ratings}$ <br/>\n",
    "$\\hat{R}\\ - \\text{predictions of your model}$ <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaebf724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(R,R_hat,index):\n",
    "    \"\"\"\n",
    "    Calculates RMSE between true ratings R and ratings estimations R_hat for index.\n",
    "    params:\n",
    "         R (np.array): rank 2 matrix of (ground) true ratings\n",
    "         R_hat (np.array): rank 2 matrix of ratings' predictions R.shape = R_hat.shape\n",
    "         index (np.array): index of R and R_hat for which RMSE needs to be calculated\n",
    "    returns:\n",
    "         RMSE value\n",
    "        \n",
    "    \"\"\"\n",
    "    #YOUR TASK: implement RMSE\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5eb57e",
   "metadata": {},
   "source": [
    "### 3. Prepare error metrics HR@n (please solve after you implement MF with ALS)\n",
    "\n",
    "Your task: write a function that calculates HR@n\n",
    "\n",
    "HR(u)@n for a single user u is calculated when the number of recommended items for that user is n. If out of n recommended items m (m<=n) were consumed by user then:\n",
    "\n",
    "#### $HR@n(u) = \\frac{m}{n}$ <br/>\n",
    "\n",
    "Overall HR@n is just an average over all users:\n",
    "#### $HR@n = \\frac{1}{n_u} \\sum{\\frac{m}{n}}$ <br/>\n",
    " \n",
    "be careful with caveats with HR!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8174d653",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HR_at_n(R,R_hat,R_exclude,n=10):\n",
    "    \"\"\"\n",
    "    Calculates RMSE between true ratings R and ratings estimations R_hat for index.\n",
    "    params:\n",
    "         R (np.array): rank 2 matrix of (ground) true ratings\n",
    "         R_hat (np.array): rank 2 matrix of ratings' predictions R.shape = R_hat.shape\n",
    "         R_exclude (np.array): rank 2 matrix of ratings to be excluded i.e. if R_exclude[u,i]>0 then item i for user u has to be excluded from HR calculation (e.g. it was used for training)\n",
    "         n (int): length of recommendation\n",
    "    returns:\n",
    "         RMSE value\n",
    "        \n",
    "    \"\"\"\n",
    "    #YOUR TASK: implement HR@n function\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cac23ff",
   "metadata": {},
   "source": [
    "### 4.Plotting function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949a39e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(model):\n",
    "    \"\"\"visualize the training/testing loss\"\"\"\n",
    "    linewidth = 1\n",
    "    \n",
    "    fig = plt.figure(figsize=(15,5))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(model.test_rmse_record, label = 'Test', linewidth = linewidth)\n",
    "    plt.plot(model.train_rmse_record, label = 'Train', linewidth = linewidth)\n",
    "    plt.xlabel('iterations')\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.legend(loc = 'best')\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(model.test_hr, label = 'Test', linewidth = linewidth)\n",
    "    plt.plot(model.train_hr, label = 'Train', linewidth = linewidth)\n",
    "    plt.xlabel('iterations')\n",
    "    plt.ylabel('HR@{}'.format(model.hr_n))\n",
    "    plt.legend(loc = 'best')\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(model.loss, label = 'train loss', linewidth = linewidth)\n",
    "    plt.xlabel('steps')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(loc = 'best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377371a2",
   "metadata": {},
   "source": [
    "### 4. Main part: iplementation of ALS, but batched version\n",
    "\n",
    "Your task: implement a ALS MF batched recommender. This is iterative algorithm and MF_ALS class implements it.\n",
    "    \n",
    "#### 1. We will factorise rating matrix R so that $R\\approx \\hat{R}= XY^T$ , \n",
    "#### 2. Every step of this iteration calculates X and Y which are in fact embeedings for users (X) and items (Y) and there will be n_iters iterations (epochs), however now each update will be based on the batch of data rather than entire matrix R\n",
    "#### 3. $X \\in R^{n_u\\ x\\ \\text{n_factors}}$ $Y \\in R^{n_i\\ x\\ \\text{n_factors}}$ X, Y can be initialised uniformlly [0,1]\n",
    "#### 4. We want it to be a regularised version of ALS (reg>0), but you can start without it for simplicity\n",
    "#### 5. After every iteration we want to log the RMSE,  HR@n and train loss using functions that you have developed above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77aa2991",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF_ALS_Batched:\n",
    "    \"\"\"\n",
    "    Train a matrix factorization model using Alternating Least Squares\n",
    "    to predict empty entries in a matrix\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_iters : int\n",
    "        number of iterations to train the algorithm\n",
    "        \n",
    "    n_factors : int\n",
    "        number of latent factors to use in matrix \n",
    "        factorization model, some machine-learning libraries\n",
    "        denote this as rank\n",
    "        \n",
    "    reg : float\n",
    "        regularization term for item/user latent factors,\n",
    "        since lambda is a keyword in python we use reg instead\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_iters, n_factors, reg):\n",
    "        self.reg = reg\n",
    "        self.n_iters = n_iters\n",
    "        self.n_factors = n_factors  \n",
    "        \n",
    "\n",
    "    def fit(self,train,test,lr=0.01,BS=1000,n=10):\n",
    "        #YOUR TASK 1: get arrays of user_ids and item_ids and corresponding ratings\n",
    "        u_id=#GET ALL users\n",
    "        i_id=#GET ALL items\n",
    "        r = #GET ALL ratings\n",
    "        self.n_user, self.n_item =np.max(u_id)+1, np.max(i_id)+1\n",
    "        #YOUR TASK 2: initialise X, Y uniformly [0,1]\n",
    "        self.user_factors = #RANDOM INIT\n",
    "        self.item_factors = #RANDOM INIT\n",
    "        n_cnt = u_id.shape[0] # dataset size     \n",
    "        self.test_rmse_record  = []\n",
    "        self.train_rmse_record = []\n",
    "        self.loss = []\n",
    "        self.test_hr = []\n",
    "        self.train_hr = []\n",
    "        self.hr_n = n \n",
    "        for e in range(self.n_iters):\n",
    "            for b in range(u_id.shape[0]//BS):\n",
    "                #YOUR TASK3: get boundaries of batch and all ratings (R_batch) that are in this batch \n",
    "                bmin = #min boundary\n",
    "                bmax = #max boundary\n",
    "                R_batch = np.zeros(shape=(self.n_user,self.n_item))\n",
    "                R_batch[u_id[bmin:bmax],i_id[bmin:bmax]] = r[bmin:bmax]\n",
    "                #YOUR TASK4: calculate train loss (for logging), remember about regularisation\n",
    "                L = -1\n",
    "                self.loss.append(L)\n",
    "                #YOUR TASK5: calculate derivative of loss with respect to X and Y, update X, Y\n",
    "                dX = -1\n",
    "                self.user_factors = self.user_factors - lr*dX\n",
    "                dY = -1\n",
    "                self.item_factors = self.item_factors - lr*dY\n",
    "            predictions = self.predict()\n",
    "            test_rmse = self.compute_rmse(test, predictions)\n",
    "            train_rmse = self.compute_rmse(train, predictions)\n",
    "            test_hr = self.compute_hr_at_n(test,predictions,train,n)\n",
    "            train_hr = self.compute_hr_at_n(train,predictions,np.zeros_like(train),n)\n",
    "            self.test_rmse_record.append(test_rmse)\n",
    "            self.train_rmse_record.append(train_rmse)\n",
    "            self.test_hr.append(test_hr)\n",
    "            self.train_hr.append(train_hr)\n",
    "        \n",
    "    \n",
    "    def predict(self):\n",
    "        \"\"\"predict ratings for every user and item\"\"\"\n",
    "        pred = self.user_factors.dot(self.item_factors.T)\n",
    "        return pred\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_rmse(R, R_hat):\n",
    "        \"\"\"ignore zero terms prior to comparing the mse\"\"\"\n",
    "        rmse_val = rmse(R,R_hat,R>=1)\n",
    "        return rmse_val\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_hr_at_n(R,R_hat,R_exclue,n):\n",
    "        return HR_at_n(R,R_hat,R_exclue,n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d4b315",
   "metadata": {},
   "source": [
    "#### 5. Time for test!\n",
    "\n",
    "1. What are HyperParams of this algorithm?\n",
    "2. Can you find best ones?\n",
    "3. What are conclussions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8698520",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold in range(1,6):\n",
    "    train = pd.read_csv('ml-100k/u{}.base'.format(fold), header=None, names=['user_id', 'item_id', 'rating', 'timestamp'], \n",
    "                             delim_whitespace=True)\n",
    "    test = pd.read_csv('ml-100k/u{}.test'.format(fold), header=None, names=['user_id', 'item_id', 'rating', 'timestamp'], \n",
    "                             delim_whitespace=True)\n",
    "    #YOUR TASK: get train and test R, fit the model, plot learning curve\n",
    "    print (fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75e4088",
   "metadata": {},
   "source": [
    "#### 6. How to modify the above code so that:\n",
    "\n",
    "We would have ratings {0,1} only instead of {1,2,3,4,5}. What will it change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcee194",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
